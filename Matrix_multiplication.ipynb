{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled1.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyMU2it4PKy8JPQkMfEUukLb",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/HEKOCMOC/HPC_LAB/blob/main/Matrix_multiplication.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aJxmSgIyrYCZ",
        "outputId": "004cdfd3-a807-487b-cb95-39f4daccbf68"
      },
      "source": [
        "%pylab inline"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Populating the interactive namespace from numpy and matplotlib\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/IPython/core/magics/pylab.py:161: UserWarning: pylab import has clobbered these variables: ['datetime', 'float64']\n",
            "`%matplotlib` prevents importing * from pylab and numpy\n",
            "  \"\\n`%matplotlib` prevents importing * from pylab and numpy\"\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o4HIVpUarbeb",
        "outputId": "676977e9-4e8f-4c99-b5fd-299d0191e380"
      },
      "source": [
        "import math\n",
        "import numpy as np\n",
        "from numba import cuda, jit, float64, prange\n",
        "from numba.cuda import jit \n",
        "import time\n",
        "from datetime import datetime \n",
        "\n",
        "cuda.detect()"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 1 CUDA devices\n",
            "id 0            b'Tesla K80'                              [SUPPORTED]\n",
            "                      compute capability: 3.7\n",
            "                           pci device id: 4\n",
            "                              pci bus id: 0\n",
            "Summary:\n",
            "\t1/1 devices are supported\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DoTH_1WItIvh"
      },
      "source": [
        "N = 2000\n",
        "A = np.random.randn(N, N)\n",
        "B = np.random.randn(N, N)\n",
        "C = np.zeros((N, N))"
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "88SCFSHPu-1n",
        "outputId": "1e298140-f948-4b5e-bd22-f8f5002a8b4c"
      },
      "source": [
        "def matmul_CPU(A, B, C):\n",
        "  for i in range(C.shape[0]):\n",
        "    for j in range(C.shape[1]):\n",
        "      sum = 0\n",
        "      for k in range(A.shape[1]):\n",
        "        sum += A[i, k] * B[k, j]\n",
        "      C[i, j] = sum\n",
        "      return C\n",
        "host_1 = C\n",
        "\n",
        "%time _= matmul_CPU(A, B, C)\n",
        "start = datetime.now()\n",
        "matmul_CPU(A, B, C)\n",
        "print('--------------------------------------')\n",
        "print('Matmul on CPU:', datetime.now() - start)\n",
        "print('--------------------------------------')\n"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 1.84 ms, sys: 0 ns, total: 1.84 ms\n",
            "Wall time: 1.88 ms\n",
            "--------------------------------------\n",
            "Matmul on CPU: 0:00:00.001982\n",
            "--------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qH8N7wDc1LdY",
        "outputId": "ff6e8107-d9c6-4f45-b871-93a8b5688e15"
      },
      "source": [
        "@cuda.jit\n",
        "def matmul_GPU(A, B, C):\n",
        "  i, j = cuda.grid(2)\n",
        "  if i < C.shape[0] and j < C.shape[1]:\n",
        "    sum = 0\n",
        "    for k in range(A.shape[1]):\n",
        "      sum += A[i, k] * B[k, j]\n",
        "    C[i, j] = sum\n",
        "\n",
        "def host_naive(A, B, C):\n",
        "  d_A = cuda.to_device(A)\n",
        "  d_B = cuda.to_device(B)\n",
        "  d_C = cuda.device_array(C.shape, np.float64)\n",
        "\n",
        "  threadsperblock = (16, 16)\n",
        "  blockspergrid_x = math.ceil(A.shape[0]/threadsperblock[0])\n",
        "  blockspergrid_y = math.ceil(B.shape[1]/threadsperblock[1])\n",
        "  blockspergrid = (blockspergrid_x, blockspergrid_y)\n",
        "\n",
        "  matmul_GPU[blockspergrid, threadsperblock](d_A, d_B, d_C)\n",
        "  return d_C.copy_to_host()\n",
        "\n",
        "host_2 = C\n",
        "%time _= host_naive(A, B, C)\n",
        "start = datetime.now()\n",
        "host_naive(A, B, C)\n",
        "print('--------------------------------------')\n",
        "print('Matmul on GPU:', datetime.now() - start)\n",
        "print('--------------------------------------')\n",
        "\n"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 1.34 s, sys: 8.82 ms, total: 1.35 s\n",
            "Wall time: 1.35 s\n",
            "--------------------------------------\n",
            "Matmul on GPU: 0:00:00.946033\n",
            "--------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9k_JPhKi8dbb",
        "outputId": "e1c0e774-5b72-4487-f0d6-4dcd53acc361"
      },
      "source": [
        "print('Проверка корректности перемножения матриц') \n",
        "print('Если матрицы равны, то будет True:', np.allclose(host_1, host_2))"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Проверка корректности перемножения матриц\n",
            "Если матрицы равны, то будет True: True\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U8cpemYQD2zB"
      },
      "source": [
        ""
      ],
      "execution_count": 6,
      "outputs": []
    }
  ]
}