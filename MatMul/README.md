# Лабораторная работа 1 :octocat:
## Перемножение матриц
**Задача**: реализовать алгоритм перемножения матриц<br/>
**Язык**: Python<br/>
**Входные данные**: 2 матрицы размером от 100 х 100 до 2000 х 2000 каждая<br/>
**Выходные данные**: проверка корректности перемножения + время вычисления<br/>
## **Техническое обеспечение**
+ Процессор: Intel(R) Xeon(R) CPU @ 2.30GHz
+ Графический процессор: Tesla K80
+ Чип: Apple M1 (для сравнения с вычислениями, полученными с Google Colaboratory)
## **Описание**
Язык Python 3.7 с использованием библиотек Numba, Numpy.
В программе реализованы четыре функции: 
+ ```CPU_matmul_dot``` - функция перемножение матриц на CPU с помощью встроенной функции ```np.dot()``` в библиотеке Numpy.
+ ```CPU_matmul``` - функция перемножение матриц на CPU.
+ ```CPU_matmul_jit``` - функция перемножение матриц на CPU с использованием декоратора ```@jit```.
+ ```GPU_matmul_cuda_jit``` - функция перемножения матриц на GPU с применением декоратора ```@cuda.jit```. 
Декоратор ```cuda.jit``` предназначен в первую очередь для оформления функций-ядер, поскольку только тогда поддерживаются встроенные переменные вроде ```threadIdx``` и спецификаторы типа ```__shared__```. Поэтому, если необходимо написать аналог CUDA-ядра, надо использовать декорирование ```@cuda.jit```.

## **Результаты**
В таблице приведены результаты расчета случайно сгенерированных матриц на CPU и GPU соответственно:
Размер матрицы | Расчет на CPU (np.dot), сек | Расчет на CPU, сек | Расчет на CPU (@jit), сек | Расчет на GPU, сек | Ускорение (CPU/GPU)
------------ | ------------- | ------------- | ------------- | ------------- | ------------- |
50 | 0.004 | 0.113 | 0.467 | 0.573 | 0.197
128 | 0.003 | 1.429 | 0.003 | 0.005 | 282.802
500 | 0.014 | 79.691 | 0.182 | 0.065 | 1233.712

Также были получены результаты перемножения матриц на чипе M1 с целью сравнения вычислительных способностей с CPU, предоставленной Colaboratory:
Размер матрицы | Расчет на CPU (np.dot), сек | Расчет на CPU, сек |
------------ | ------------- | ------------- |
50 | 0.0012 | 0.078 |
128 | 0.0013 | 0.752 |
500 | 0.0131 | 44.946 |
<br/>
График сравнения времени вычисления в зависимости от размера матриц (в Google Colab):
![CPU_GPU_SpeedTest](https://drive.google.com/uc?export=view&id=1BvU07aNd11TAb37qHojbSg6Yc_pQGGg6)
<br/>
График сравнения времени вычисления на CPU (M1) в зависимости от размера матриц (в jupyter):
![M1_CPU_SpeedTest](https://drive.google.com/uc?export=view&id=1RU5iBX4Q3RQ3A-q-4VqGSZG5RLGYwQ2d)
<br/>
По оси X - размер матрицы;<br/>
По оси Y - время выполнения расчета перемножения матриц.<br/>

Корректность перемножения матриц была осуществлена с помощью ```np.allclose()```, если в ответ выводилось ```True``` , значит матрицы, расчитанные двумя функциями, одинаковы.

## **Заключение**
По результат можно сделать неоднозначный вывод, с одной стороны известно, что GPU значительно ускоряет процесс вычисления различных математических задач по сравнению с вычислением на CPU. Но по полученным данным получилось всё наоборот: CPU вычисляет в 37, 100 и 695 раз быстрее, чем GPU. <br/>
Возможно, [ключевую роль](https://erik-engheim.medium.com/apple-m1-foreshadows-risc-v-dd63a62b2562) в таком превосходстве CPU сыграл чип М1 так как есть одна важная мелочь, которую нужно запомнить: М1 - это не только CPU. Это система множества чипов, лежащих в одной кремниевой обертке. CPU же - это один из этих чипов. Технически, М1 - это весь компьютер на одном чипе. Он содержит CPU, графический процессор GPU, память, контроллеры I/O и множество других вещей, делающих компьютер компьютером, так называемой системой на чипе (system on the chip, SoC).
